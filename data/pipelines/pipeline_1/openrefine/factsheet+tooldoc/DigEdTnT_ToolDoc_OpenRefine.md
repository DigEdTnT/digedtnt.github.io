# Allgemeine Beschreibung

_OpenRefine_ ist ein Open-Source-Tool zur Datenbereinigung und Datentransformation, das urspr√ºnglich als Google Refine bekannt war. Es bietet eine anwenderfreundliche grafische Benutzeroberfl√§che, mit der Daten in verschiedenen Formaten analysiert, bereinigt und strukturiert werden k√∂nnen.

_OpenRefine_ eignet sich besonders gut f√ºr die Arbeit mit gro√üen und unstrukturierten Datens√§tzen, wobei es das Filtern, Sortieren und Gruppieren von Daten sowie das Erkennen und Beheben von Fehlern und Unregelm√§√üigkeiten erm√∂glicht. Das Tool unterst√ºtzt au√üerdem auch die Zusammenf√ºhrung von Datens√§tzen aus verschiedenen Quellen und das Aufteilen von Zellen, um Daten besser zu organisieren.

<div class="essence">
In Hinblick auf digitale Editionen ist ein Vorteil von <span style="font-style:italic;">OpenRefine</span>, dass es nicht nur die Datenbereinigung, - transformation und -organisation gro√üer unstrukturierter Datenmengen erleichtert, sondern vor allem auch Funktionen zur Normalisierung von Daten sowie zur Konsolidierung von Informationen bietet. Beim Export der Daten muss man jedoch auf die M√∂glichkeit, direkt eine XML-Datei herunterzuladen, verzichten und auch komplexere Datentransformationen beim Export - wie beispielweise das Gruppieren von Daten - werden nicht unterst√ºtzt.
</div>

## Anwendungsbereiche

* Bereinigung unstrukturierter und fehlerhafter Daten
* Zusammenf√ºhrung und Konsolidierung von Daten aus verschiedenen Quellen
* Normalisierung von bestehenden Datenbest√§nden


## Funktions√ºbersicht

* Datenbereinigung bei unstrukturierten und fehlerhaften Daten (Dubletten, Tippfehler, Inkonsistenzen und andere Unregelm√§√üigkeiten)
* Datennormalisierung
* Datentransformation  (z. B. Excel/CSV-Input zu JSON oder XML-Struktur)
* Datenzusammenf√ºhrung, wenn verschiedene Quellen vorhanden sind
* M√∂glichkeit der Strukturierung von Metadaten
* Automatisierung von wiederholten Datenbereinigungs- und Transformationsaufgaben durch die Erstellung von Skripten oder Aktionen f√ºr bestimmte Aufgaben


## Voraussetzungen

Jedes Tool kann einerseits bestimmte Vorkenntnisse der Benutzer:innen voraussetzen und andererseits auch hinsichtlich der Software-Umgebung gewisse Anforderungen stellen.

### Erforderliche Kenntnisse

* [EDV-Grundkenntnisse](https://digedtnt.github.io/about/#grundvoraussetzungen)
* Ausdruckssprachen und Transformationstechniken von Vorteil


### Ben√∂tigte Software

* Stabile Internetverbindung
* Webbrowser

## Tool-Kompatibilit√§t


<div class="table-responsive tool-table">
<table class="table">
  <tr>
   <td>
   </td>
   <td>IIIF
   </td>
   <td>Transkribus
   </td>
   <td>FromThePage
   </td>
   <td>ediarum
   </td>
   <td>FairCopy
   </td>
   <td>ba[sic?]
   </td>
   <td>teiPublisher
   </td>
   <td>ediarum.WEB
   </td>
  </tr>
  <tr>
   <td>OpenRefine
   </td>
   <td>‚ùå
   </td>
   <td>‚ùå
   </td>
   <td>‚ùå
   </td>
   <td><a href="https://digedtnt.github.io/transition-openrefine-ediarum/">ü¶Ñ</a>
   </td>
   <td>‚ùå
   </td>
   <td>‚ùå
   </td>
   <td>‚ùå
   </td>
   <td>‚ùå
   </td>
  </tr>
</table>
</div>


## Kosten√ºbersicht

* kostenlos


# M√∂glichkeiten & Grenzen

Da jedes Projekt unterschiedliche Anforderungen mit sich bringt, sollen nachfolgend m√∂gliche Vor- und Nachteile des
Tools aufgelistet werden, die w√§hrend der Durchf√ºhrung des jeweiligen [Beispielprojekts](https://digedtnt.github.io/about/#rezeptsammlung-pipeline-1) festgestellt wurden.

## St√§rken

* Benutzerfreundliche Bearbeitungsoberfl√§che und Wahrung der Datensicherheit durch die lokale Bearbeitung und Speicherung
* Bereinigung von unstrukturierten und fehlerhaften Daten (Dubletten, Tippfehler, Inkonsistenzen) und damit √úberpr√ºfung der Datenqualit√§t (Qualit√§tssicherung)
* Versionskontrolle durch die M√∂glichkeit, Arbeitsschritte wieder r√ºckg√§ngig zu machen oder bereits get√§tigte Schritte wiederherzustellen
* Datenerweiterung und Normalisierung √ºber Reconciliation-Services, die den Datenabgleich mit externen Datenbanken erm√∂glichen
* Datentransformation in andere Formate oder Strukturen
* Datenzusammenf√ºhrung bei mehreren Quellen oder Versionen
* Organisation und Strukturierung von Metadaten
* Automatisierung von wiederholten Datenbereinigungs- und Transformationsaufgaben durch die M√∂glichkeit, den √Ñnderungsverlauf zu exportieren und auf neue Daten anzuwenden

## Herausforderungen & Probleme

* Keine simultane Kollaborationsm√∂glichkeit, da _OpenRefine_ f√ºr die lokale Verwendung konzipiert ist und nicht mehrere Personen gleichzeitig an einem Projekt arbeiten k√∂nnen (eine - aber bei einer Vielzahl von Projektmitarbeitenden relativ umst√§ndliche - M√∂glichkeit, mit anderen Personen zusammenzuarbeiten, besteht aber darin, Projekte inklusive der gespeicherten Bearbeitungsschritte zu exportieren und daraufhin an einem anderen Rechner zu importieren)
* Teilweise m√ºhsame Bedienung durch das Problem, dass _OpenRefine_ bei der manuellen Zuordnung von passenden Wikidata-Eintr√§gen nach jeder einzelnen Match-Best√§tigung zum Start der Tabelle springt
* Keine direkte Exportm√∂glichkeit in eine XML-Datei, wobei √ºber den Templating-Export die Daten jedoch zumindest in einer XML-Struktur (als Plaintext-Datei) exportiert werden k√∂nnen
* Komplexere Datentransformationen - wie beispielsweise das Gruppieren von Datens√§tzen anhand des Inhalts einer Zelle - sind beim Export nicht m√∂glich, wodurch Redundanzen in den Daten auftreten k√∂nnen und eine Nachbearbeitung erforderlich sein kann


# Einrichtung & Erste Schritte

Anhand unseres [Beispielprojekts](https://digedtnt.github.io/about/#rezeptsammlung-pipeline-1), das zum Ziel hat, Kochrezepte aus dem Mittelalter computergest√ºtzt zu analysieren und sp√§ter √ºber eine Forschungsplattform zur Verf√ºgung zu stellen, soll nachfolgend ein m√∂glicher Arbeitsablauf beschrieben werden. Die Manuskripte des Projektes wurden bereits mittels [FromThePage](https://digedtnt.github.io/fromthepage/) transkribiert und mit [ediarum](https://digedtnt.github.io/ediarum/) wurden bereits erste Annotationen vorgenommen. In dieser Kurzanleitung erfolgt nun die Aufbereitung der Zutatenliste, die wir von einem Historiker im CSV-Format erhalten haben. Unser Ziel ist es, die Daten zu normalisieren und sie zus√§tzlich mit den [Q-Nummern](https://www.wikidata.org/wiki/Wikidata:Glossary/de) - auch QID genannt - von Wikidata-Eintr√§gen anzureichern.


## 1. Installation

* Unser erster Schritt besteht darin, uns die entsprechende Version f√ºr unser Betriebssystem von [OpenRefine herunterzuladen](https://openrefine.org/download). Nach dem Entpacken der ZIP-Datei f√ºhren wir openrefine.exe aus, wodruch sich _OpenRefine_ direkt in unserem Browser √∂ffnet.
   ![Startbildschirm von OpenRefine](../img/openrefine-start.PNG)


## 2. Einrichtung des Projekts

* Um ein Projekt erstellen zu k√∂nnen, werden wir aufgefordert, Daten zu importieren. Wir laden daher als erstes unsere [EXCEL-Datei mit der Zutatenliste](https://github.com/DigEdTnT/digedtnt.github.io/blob/master/data/pipelines/pipeline_1/openrefine/data/list_of_ingredients.xlsx) hoch.
   ![Upload der EXCEL-Datei](../img/create-project.PNG)
* Mit dem Button "Next" kommen wir in die darauffolgende Ansicht und k√∂nnen einige Einstellungen vornehmen, bevor unser Projekt erstellt wird.
   ![Projekteinstellungen beim Import](../img/import-data.PNG)
    ‚Üí F√ºr unser Projekt haben wir an den vorausgew√§hlten Einstellungen nichts ge√§ndert und nur einen Projektnamen gew√§hlt, bevor wir mit "Create project" fortgefahren sind.
* Unsere Projektansicht sieht letztlich so aus:
   ![Projektansicht in OpenRefine](../img/project-view.PNG)
     ‚Üí Die Eintr√§ge aus der CSV-Datei werden tabellarisch dargestellt. In der ersten Spalte sind verschiedene fr√ºhneuhochdeutsche Schreibvarianten einzelner Zutaten, in der zweiten Spalte die heutige Schreibweise und in der dritten Spalte befinden sich die √úbersetzungen in modernes Englisch. Jede Spalte verf√ºgt √ºber ein Drop-Down-Men√º, das uns verschiedene Bearbeitungsm√∂glichkeiten bietet, wobei f√ºr uns vor allem jene Funktion, die eine Anreicherung mit Normdaten (Reconciliation) erm√∂glicht, von Interesse ist.


## 3. Bearbeitung der Dokumente

* Sollten wir zwischenzeitlich unser Projekt geschlossen haben, m√ºssen wir f√ºr die Arbeit in _OpenRefine_ zuerst wieder unsere Datei openrefine.exe starten, √ºber die erneut der Browser ge√∂ffnet wird. Unter **Open Project** in der linken Navigationleiste k√∂nnen wir schlie√ülich unsere Projekte einsehen. Wir √∂ffnen hier unser bereits angelegtes Projekt "MaRezepte".
   ![Einstieg zur Projektbearbeitung in OpenRefine](../img/open-project.PNG)
* Um unsere Zutatenliste mit Eintr√§gen aus einer Normdatenbank anzureichern, √ºberpr√ºfen wir zuerst, welche Eintr√§ge auf Basis der Spalte mit den englischen Begriffen gefunden werden. Wir w√§hlen hier das Englische, weil die englische Wikidata-Datenbank mit der gr√∂√üten Abdeckung an Begriffen zu einer h√∂heren Trefferquote f√ºhrt. Daf√ºr gehen wir auf die Spalte mit der √úberschrift "eng", w√§hlen im Dropdown die Option **Reconcile** und dann in der damit verbundenen Auswahl **Start Reconcile**.
   ![Auswahl an Datenbearbeitungsm√∂glichkeiten](../img/start-reconciliation.PNG)
* In dem neuen Fenster, das sich daraufhin √∂ffnet, klicken wir in der linken Men√ºleiste auf "Wikidata (en)".
   ![Start des Abgleichs mit den Normdaten von Wikidata](../img/reconciliation-service.PNG)
* In dem nachfolgenden Fenster w√§hlen wir folgende Einstellungen:
    * Bei der Kategorienzuordnung, mit der festgelegt werden kann, dass die Begriffe nur mit Entit√§ten einer bestimmten Kategorie abgeglichen werden, m√∂chten wir uns nicht zu sehr einschr√§nken. Wir k√∂nnten nat√ºrlich nur "food ingredients" ausw√§hlen, aber erstens sind nicht alle Entit√§ten einer Kategorie zugewiesen und zweitens ist die Kategoriezuordnung nicht immer eindeutig, weshalb beispielsweise einer Zutat wie Petersilie anstelle der Kategorie "Zutat", auch einfach nur die Kategorie "Pflanze" zugeordnet sein k√∂nnte. Um zu verhindern, dass durch die Einschr√§nkung auf eine bestimmte Kategorie m√∂glicherweise unkategorisierte oder abweichend kategorisierte Entit√§ten nicht mit unseren Daten abgeglichen werden, nutzen wir die Option: "Reconcile against no particular type".
    * Zus√§tzlich gibt es die M√∂glichkeit, √ºber die Checkbox "Auto-match candidates with high confidence" einzustellen, dass bei jenen Begriffen, f√ºr die mit hoher Wahrscheinlichkeit eine passende Wikidata-Entit√§t gefunden wurde, eine automatische Zuordnung vorgenommen wird.
* Mit diesen Einstellungen f√ºr unsere Daten starten wir schlie√ülich den Reconciliation-Prozess.
   ![Diverse Einstellungen vor dem Start des Reconciliation-Prozesses](../img/reconciliation-options.PNG)
    ‚Üí Dieser Prozess kann je nach Datenmenge ein paar Minuten dauern.
   ![Unterschiedlich lange Wartezeiten je nach Datenmenge](../img/reconciliation-processing.PNG)
* **Kleiner Exkurs bei alternativen Daten:** Wenn wir die Begriffe nicht auch Englisch, sondern nur im Standarddeutsch h√§tten, m√ºssten wir √ºber den Button "Add standard service" ein weiteres Service  f√ºr das deutsche Wikidata anlegen, indem wir die entsprechende URL zur API eingeben.
   ![Verkn√ºpfung mit der API zu den deutschsprachigen Wikidata-Eintr√§gen](../img/add-reconciliation-service.PNG)
    In unserer linken (und √ºber ein kleines Lesezeichen-Symbol ein- und ausklappbaren) Liste erscheint nun ein Button f√ºr die Reconciliation von Begriffen mit deutschsprachigen Wikidata-Eintr√§gen, die wir dann entsprechend f√ºr eine Spalte mit deutschsprachigen Begriffen ausw√§hlen k√∂nnten.
   ![Auswahl eines anderen Services](../img/choose-reconciliation-service.PNG)
    ‚Üí Hinter dem Button "Discover Services" verbergen sich au√üerdem [noch weitere Normdaten-Ressourcen](https://reconciliation-api.github.io/testbench/#/).
* Sobald der Reconciliation-Prozess abgeschlossen ist, erhalten wir in der Header-Zeile der Spalte einen √úberblick zu unserem Fortschritt in Form eines Balkens. Aus unserer Tabelle mit 536 Zeilen wurde knapp ein F√ºnftel automatisiert mit Normdaten angereichert und f√ºr √ºber 80% der Eintr√§ge ist noch eine manuelle √úberpr√ºfung n√∂tig, da es hier mehrere Entit√§ten gibt, die mit dem Begriff aus der jeweiligen Zeile √ºbereinstimmen.
   ![Auswertung des Reconciliation-Prozesses](../img/reconciliation-result.PNG)
    ‚Üí Zus√§tzlich bekommen wir in der linken Leiste Informationen zu den Matches und haben auch die M√∂glichkeit, den Prozess r√ºckg√§ngig zu machen.
* Bei allen Begriffen, f√ºr die nicht automatisch eine Entsprechung aus den Wikidata-Normaten √ºbernommen wurde, m√ºssen wir nun eine manuelle Zuordnung vornehmen. Durch die √úbersetzung der verschiedenen Schreibweisen f√ºr einen konkreten Begriff haben wir im Englischen sehr viele gleiche Eintr√§ge. Damit wir nicht jeden Zeile einzeln durchgehen m√ºssen, gibt es in _OpenRefine_ die M√∂glichkeit, das K√§stchen mit dem doppelten H√§kchen zu verwenden, um den entsprechenden Wikidata-Eintrag f√ºr alle identischen Zellen zu √ºbernehmen.
   ![Gleichzeitige Zuordnung eines Wikidata-Eintrages f√ºr alle identischen Zellen](../img/reconcile-all-matches.PNG)
    ‚Üí Etwas m√ºhsam bei dieser manuellen Zuordnung ist, dass nach jeder √úbernahme eines Wikidata-Eintrags das Programm anschlie√üend zum Start der Tabelle h√ºpft, und man daher anschlie√üend immer erneut zur n√§chsten, zur Bearbeitung ausstehenden Zeile scrollen muss.
* Sollte in den Vorschl√§gen eine passende Wikidata-Entsprechung fehlen, gibt es am Ende der Liste die M√∂glichkeit, nach weiteren √úbereinstimmungen zu suchen und im neuen Suchfenster schlie√ülich weitere Eingaben, unter denen ein Begriff auch zu finden sein k√∂nnte, vorzunehmen.
   ![Suche nach alternativen Wikidata-Eintr√§gen](../img/search-for-matches.PNG)
    ‚Üí In unserem Datensatz wurde zum Beispiel das englische Wort "horse radish" mit einem Leerzeichen geschrieben, weshalb in der Liste mit Vorschl√§gen kein passender Eintrag zu finden war.
* Sollten wir mit einer unserer Zuordnungen nicht zufrieden sein, gibt es zwei M√∂glichkeiten, die Zuordnung wieder r√ºckg√§ngig zu machen. Entweder wir klicken einfach auf "Choose new match", direkt unter dem Begriff, der falsch zugeordnet wurde (a.), oder wir gehen in der linken Men√ºleiste in den Reiter **Undo/Redo** und w√§hlen einen vorangegangen Schritt aus, um dort wieder weiterzumachen (b.).
   ![Zwei M√∂glichkeiten, unpassende Zuordnungen zu √§ndern oder zur√ºckzusetzen](../img/undo-processes.PNG)
    ‚Üí Mit dem "Extract"-Button in der linken Men√ºleiste ist es au√üerdem m√∂glich, entweder alle oder einen Teil der bereits get√§tigten Schritte zu exportieren. Sollte sich die Liste beispielsweise erheblich ver√§ndern, so k√∂nnte man ein neues Projekt erstellen, und den bisherigen Arbeitsfortschritt √ºber den Import der Arbeitsschritte (mittels "Apply"-Button) wiederherstellen. Anschlie√üend m√ºsste man anschlie√üend nur mehr die neu hinzugekommenen Eintr√§ge mit Wikidata-Normdaten angereichert werden.
* F√ºr Eintr√§ge, die man nicht mit Normdaten anreichern m√∂chte oder nicht kann, weil wie in unserem Beispielprojekt mitunter nicht jede Zutat entschl√ºsselt wurde, gibt es die M√∂glichkeit, √ºber die Ansicht, die unter "Search for match" erscheint, auszuw√§hlen, dass der Zelle kein Eintrag zugeordnet werden soll.
   ![Eintrag ohne Zuordnung einer Wikidata-Entit√§t](../img/unsolved-entries.PNG)
* Sobald wir all unsere Eintr√§ge mit Wikidata-Eintr√§gen angereichert haben, k√∂nnen wir uns die Q-Nummern der Wikidata-Eintr√§ge in einer eigenen Spalte anzeigen lassen.
   ![Spalte mit Daten der Normalisierung hinzuf√ºgen](../img/add-qid.PNG)
    Wir m√ºssen dieser Spalte nur mehr einen Namen geben und jede Zeile erh√§lt eine weitere Zelle mit der entsprechenden Q-Nummer.
   ![Q-Nummern f√ºr jeden Eintrag in eigener Spalte](../img/wikidata-column.PNG)
    ‚Üí Wir haben uns f√ºr "idno" entschieden, da wir sp√§ter beim Exportieren diesen Begriff direkt als Attributsbezeichnung √ºbernehmen wollen und als Wert die entsprechende Q-Nummer eingef√ºgt werden soll.


## 4. Export der Dokumente

* Um unsere angereicherte Tabelle bzw. normalisierten Daten zu exportieren, klicken wir auf den Button "Export" und w√§hlen die Option "Templating". Denn unser Ziel ist es, direkt eine XML-Struktur zu generieren, die wir anschlie√üend in unser Register in _ediarum_ √ºbernehmen k√∂nnen.
   ![Export der Daten √ºber ein Template](../img/export-data.PNG)
* In der Ansicht f√ºr die Template-Erstellung haben wir nun die M√∂glichkeit, unsere Daten so zu gestalten, dass sie nur mehr in das _ediarum_-Sachregister kopiert werden m√ºssen. Daf√ºr tragen wir in das Prefix-Textfeld `<list>` und als Suffix `</list>` ein. Entsprechend dem Schema f√ºr Register in _ediarum_ m√∂chten wir f√ºr jede Zeile einen eigenen `<item>`-Eintrag erhalten. Als @xml:id soll die englische √úbersetzung √ºbernommen werden. Den Wikidata-Link √ºbernehmen wir in Form eines `<idno>`-Elemente innerhalb des `<item>`-Elements. Au√üerdem legen wir auch 1-2 `<label>`-Elemente an, einmal mit dem Wert "reg" im @type-Attribut f√ºr die √úbersetzung in Standarddeutsch, und ein weiteres mit dem Wert "alt", das die fr√ºhneuhochdeutschen Bezeichnung enth√§lt.
In der Vorschau rechts sehen wir auch, wie unser Output schlie√ülich aussehen wird.
   ![Individuelle Anpassung des Outputs √ºber die Templating-Methode](../img/templating-export.PNG)
    ‚Üí <span style="text-decoration:underline;">Erl√§uterungen zum Code im Textfeld "Row Template":</span> Unser Code, der √ºber die einzelnen Zeilen unserer Tabelle iteriert, soll hier noch etwas genauer betrachtet werden. Mittels der [General Refined Expression Language (GREL)](https://openrefine.org/docs/manual/grel) haben wir unseren Code entsprechend unseren Anforderungen gestaltet.
    ```plaintext
    <item xml:id="{{ if(cells['eng'].value != 'unsolved', cells['eng'].value, cells['deu-enh'].value + '_unsolved') }}">
        {{ if(cells['idno'].value !=    'null', '<idno type="uri">https://www.wikidata.org/entity/' + cells['idno'].value + '</idno>', '') }}
        {{ if(cells['deu'].value != 'ungel√∂st', '<label type="reg">' + cells['deu'].value + '</label>', '<label type="reg">' + cells['deu'].value + '(' + cells['deu-enh'].value + ')</label>') }}
        <label type="alt">{{ cells['deu-enh'].value }}</label>
    </item>
    ```
    Wir haben f√ºr unsere Daten zus√§tzliche Bedingungen f√ºr folgende Spezialf√§lle eingef√ºhrt:
    * **Fehlende √úbersetzungen:** Sollten Zellen in unserem Datensatz in der englischen Spalte "unsolved" bzw. in der deutschen Spalte "ungel√∂st" beinhalten, weil man nicht wei√ü, welche Bedeutung der fr√ºhneuhochdeutsche Begriff hat, nutzen wir das fr√ºhneuhochdeutsche Wort als @xml:id.
    * **Fehlende Q-Nummer:** Sollte eine Zeile keine Q-Nummer besitzen, wird auch kein `<idno>`-Element angelegt.
* Wenn unser Output schlie√ülich so aussieht wie wir ihn gerne h√§tten, m√ºssen wir nur mehr auf den "Export"-Button klicken und eine [TXT-Datei](https://github.com/DigEdTnT/digedtnt.github.io/blob/bb032626aee08b43c4b36da5476ae9ce0d63bb2a/data/pipelines/pipeline_1/openrefine/data/output_openrefine.txt) wird heruntergeladen. F√ºr unser Beispielprojekt m√ºssen wir diesen Output aber im Anschluss noch ein wenig anpassen (siehe [Transition OpenRefine ‚Üí ediarum](https://digedtnt.github.io/transition-openrefine-ediarum/)).


# Kontakt

**Weblink:** [https://openrefine.org/](https://openrefine.org/)

<table>
  <tr>
   <td>Allgemeiner Support
   </td>
   <td><a href="https://forum.openrefine.org/c/support/12">Forum</a>
   </td>
  </tr>
  <tr>
   <td>Christian Steiner (DH Craft)
   </td>
   <td><a href="mailto:christian.steiner@dhcraft.org">christian.steiner@dhcraft.org</a>
   </td>
  </tr>
</table>



# Ressourcen


## Dokumentation

* [Offizielle OpenRefine Dokumentation](https://openrefine.org/docs)
* [Reconciliation mit Wikibase](https://openrefine.org/docs/manual/wikibase/reconciling)
* [Github-Repository](https://github.com/OpenRefine/OpenRefine)


## Tutorials

* [Using OpenRefine to Clean Your Data](https://multimedia.journalism.berkeley.edu/tutorials/openrefine/)
* [Get Started with OpenRefine: Explore, Clean, and Transform your Data!](https://www.youtube.com/watch?v=yTJ6x6zEQmI)
* [Reconciliation with Wikidata](https://www.wikidata.org/wiki/Wikidata:Tools/OpenRefine/Editing/Tutorials/Basic_editing)


## Projekte, die dieses Tool genutzt haben

* [CoReMa - Cooking Recipes of the Middle Ages](https://gams.uni-graz.at/context:corema): Im Projekt CoReMA wurden mittelalterliche Kochrezepte ediert. Mit den zugrundeliegenden Forschungsfragen sollten die kulinarischen Beziehungen zwischen Frankreich und den deutschsprachigen L√§ndern untersucht werden, auf welche die franz√∂sische Kultur von jeher einen gro√üen Einfluss hatte. Das Projekt stellt die transkribierten und annotierten Kochrezepte der deutschsprachigen √úberlieferung vor 1500 zur Verf√ºgung. In den historischen Texten sind Zutaten, K√ºchenger√§te und Speisegattungen mit modernen Normdaten annotiert. Diese werden f√ºr unterschiedliche Analyse- und Auswertungsmethoden herangezogen.



## Literatur

* Crossley, L. (2019, Oktober 29). _Text Mining Digital Humanities Blogs with APIs, OpenRefine, and R_. [https://mars.gmu.edu/handle/1920/11632](https://mars.gmu.edu/handle/1920/11632)
* Delpeuch, A. (2019). _A survey of OpenRefine reconciliation services_ (arXiv:1906.08092). arXiv. [https://doi.org/10.48550/arXiv.1906.08092](https://doi.org/10.48550/arXiv.1906.08092)
* Dre√üen, A., & Sacher, E. (2023, M√§rz 6). _Querying Art History Data on the Web (5): Modelling Data with OpenRefine_. [https://www.db-thueringen.de/receive/dbt_mods_00055804](https://www.db-thueringen.de/receive/dbt_mods_00055804)
* Engelhardt, F., Freitag, N., & Wildermuth, M. (2023). Die Migration der Bibliographia Cartographica: Daten aufr√§umen mit OpenRefine. _Bibliotheksdienst_, _57_(2), 95‚Äì110. [https://doi.org/10.1515/bd-2023-0016](https://doi.org/10.1515/bd-2023-0016)
* Gallant, K., Lorang, E., & Ramirez, A. (2014). _Tools for the digital humanities‚ÄØ: a librarian‚Äôs guide_ (Emerging Technologies in Libraries). [https://mospace.umsystem.edu/xmlui/handle/10355/44544](https://mospace.umsystem.edu/xmlui/handle/10355/44544)
* Guti√©rrrez De la Torre, Silvia Eunice. (2021, Juni 15). _OpenRefine, Authority Control and Wikidata_. [https://zenodo.org/record/4950866](https://zenodo.org/record/4950866)
* Handelman, M. (2015). Digital Humanities as Translation: Visualizing Franz Rosenzweig‚Äôs Archive. _TRANSIT_, _10_(1). [https://doi.org/10.5070/T7101029573](https://doi.org/10.5070/T7101029573)
* Ikoniƒá Ne≈°iƒá, M., Stankoviƒá, R., Sch√∂ch, C., & Skoric, M. (2022). From ELTeC Text Collection Metadata and Named Entities to Linked-data (and Back). _Proceedings of the 8th Workshop on Linked Data in Linguistics within the 13th Language Resources and Evaluation Conference_, 7‚Äì16. [https://aclanthology.org/2022.ldl-1.2](https://aclanthology.org/2022.ldl-1.2)
* Krimmel, Erica, & Walker, Lindsay J. (2022, Mai 11). _Using OpenRefine for natural history collections data_. Society for the Preservation of Natural History Collections (SPNHC), Edinburgh, Scotland, UK, 5-10 June 2022, Edinburgh, Scotland, UK,. [https://zenodo.org/record/6574729](https://zenodo.org/record/6574729)
* Mandal, S. (2022). Integration of Linked Open Data Authorities with OpenRefine‚ÄØ: A Methodology for Libraries. _Library Philosophy and Practice (e-journal)_. [https://digitalcommons.unl.edu/libphilprac/7195](https://digitalcommons.unl.edu/libphilprac/7195)
* Myntti, J., & Neatrour, A. (2015). Use Existing Data First: Reconcile Metadata before Creating New Controlled Vocabularies. _Journal of Library Metadata_, _15_(3‚Äì4), 191‚Äì207. [https://doi.org/10.1080/19386389.2015.1099989](https://doi.org/10.1080/19386389.2015.1099989)
* Ransom, L., & Coladangelo, L. P. (2021, Dezember 3). Semantic Enrichment of the Schoenberg Database of Manuscripts Name Authority through Wikidata. _15th International Conference on Metadata and Semantics Research_. [https://www.academia.edu/63137370/Semantic_Enrichment_of_the_Schoenberg_Database_of_Manuscripts_Name_Authority_through_Wikidata](https://www.academia.edu/63137370/Semantic_Enrichment_of_the_Schoenberg_Database_of_Manuscripts_Name_Authority_through_Wikidata)
* Sohmen, L., & Rossenova, L. (2022). Open refine to wikibase: a new data upload pipeline. _Proceedings of the 22nd ACM/IEEE Joint Conference on Digital Libraries_, 1‚Äì2. [https://doi.org/10.1145/3529372.3530919](https://doi.org/10.1145/3529372.3530919)
* Steeg, F., & Pohl, A. (2021). Ein Protokoll f√ºr den Datenabgleich im Web am Beispiel von OpenRefine und der Gemeinsamen Normdatei (GND). In M. Franke-Maier, A. Kasprzik, A. Ledl, & H. Sch√ºrmann (Hrsg.), _Qualit√§t in der Inhaltserschlie√üung_ (S. 259‚Äì278). De Gruyter. [https://doi.org/10.1515/9783110691597-013](https://doi.org/10.1515/9783110691597-013)
* Woitas, Kathi. (2021, Dezember 13). _OpenRefine_. [https://zenodo.org/record/5776098](https://zenodo.org/record/5776098)


# Factsheet

<table>
  <tr>
   <td colspan="2" style="text-align: center;font-size: 1.2em" ><strong>System</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Scope des Tools</strong>
   </td>
   <td>Datenbereinigung & Normalisierung
   </td>
  </tr>
  <tr>
   <td><strong>Softwareumgebung/Softwaretyp
</strong>(Remotesystem im Browser / Lokaler Client)
   </td>
   <td>lokale Browser-Anwendung
   </td>
  </tr>
  <tr>
   <td><strong>Unterst√ºtzte Plattformen</strong>
   </td>
   <td>Linux, Windows & Mac
   </td>
  </tr>
  <tr>
   <td><strong>Ger√§te</strong>
   </td>
   <td>Desktop
   </td>
  </tr>
  <tr>
   <td><strong>Einbindung anderer Systeme (Interoperabilit√§t)</strong>
   </td>
   <td> ‚úÖ  (Wikidata, Wikibase)
   </td>
  </tr>
  <tr>
   <td><strong>Accountsystem</strong>
   </td>
   <td> ‚ùå (keine Anmeldung erforderlich)
   </td>
  </tr>
  <tr>
   <td><strong>Kostenmodell  <br/>
</strong>(Kosten√ºbersicht / Open Source)
   </td>
   <td>kostenlos
   </td>
  </tr>
  <tr>
   <td colspan="2" style="text-align: center;font-size: 1.2em" ><strong>Anforderungen & Methoden</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Erforderte Code Literacy</strong>
   </td>
   <td> sehr gering
   </td>
  </tr>
  <tr>
   <td><strong>Interface-Sprachen (ISO 639-1)</strong>
   </td>
   <td>en
   </td>
  </tr>
  <tr>
   <td><strong>Unterst√ºtzte Zeichenkodierung</strong>
   </td>
   <td>UTF-8, UTF-16, ASCII
   </td>
  </tr>
  <tr>
   <td><strong>Inkludierte Datenkonvertierung</strong><br/>
(Im Pre-Processing m√∂gliche Anpassung der Daten an f√ºr die Software erforderliches Format)
   </td>
   <td>‚úÖ
   </td>
  </tr>
  <tr>
   <td><strong>Abh√§ngigkeit von anderer Software <br/>
</strong>(Falls ja, wird diese Software automatisch mitinstalliert?)
   </td>
   <td>‚ùå
   </td>
  </tr>
  <tr>
   <td><strong>Erforderliche Plug-Ins </strong>(bei web-basierten Anwendungen)
   </td>
   <td>‚ùå
   </td>
  </tr>
  <tr>
   <td colspan="2" style="text-align: center;font-size: 1.2em" ><strong>Dokumentation & Support</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Wartung und st√§ndige Erweiterung</strong>
   </td>
   <td>‚úÖ
   </td>
  </tr>
  <tr>
   <td><strong>Einbindung der Community</strong>
   </td>
   <td>‚úÖvia Github & Forum
   </td>
  </tr>
  <tr>
   <td><strong>Dokumentation</strong>
   </td>
   <td>‚úÖ
   </td>
  </tr>
  <tr>
   <td><strong>Dokumentationssprache</strong>
   </td>
   <td>Englisch
   </td>
  </tr>
  <tr>
   <td><strong>Dokumentationsformat</strong>
   </td>
   <td>HTML
   </td>
  </tr>
  <tr>
   <td><strong>Dokumentationsabschnitte</strong>
   </td>
   <td>Introduction, Installing, Running, Starting a project, Exploring data, Transforming data, Reconciling, Wikibase, Wikidata, and Wikimedia Commons, Expressions, Exporting, Troubleshooting, GREL Reference, Technical Reference
   </td>
  </tr>
  <tr>
   <td><strong>Verf√ºgbarkeit von Tutorials</strong>
   </td>
   <td>‚úÖBlogbeitrag mit Sammlung an Tutorials
   </td>
  </tr>
  <tr>
   <td><strong>Aktiver Support/Community  <br/>
</strong>(Forum, Slack, Issue Tracker etc.)
   </td>
   <td>‚úÖForum, GitHub-Issues-Mechanismus
   </td>
  </tr>
  <tr>
   <td colspan="2" style="text-align: center;font-size: 1.2em" ><strong>Nutzbarkeit & Nachhaltigkeit</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Installationsablauf </strong>
   </td>
   <td>sehr einfach
   </td>
  </tr>
  <tr>
   <td><strong>Test</strong>
<br/>
(Gibt es ein Test Suite, um zu √ºberpr√ºfen, ob die Installation erfolgreich war?)
   </td>
   <td>‚úÖ
   </td>
  </tr>
  <tr>
   <td><strong>Lizenz, unter der das Tool ver√∂ffentlicht wurde</strong>
   </td>
   <td><a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>
   </td>
  </tr>
  <tr>
   <td><strong>Registrierung in einem Repository</strong>
   </td>
   <td>‚úÖ Github
   </td>
  </tr>
  <tr>
   <td><strong>M√∂glichkeit zur Software-Entwicklung beizutragen</strong>
   </td>
   <td>‚úÖ
   </td>
  </tr>
  <tr>
   <td colspan="2" style="text-align: center;font-size: 1.2em" ><strong>Benutzerinteraktion & Benutzeroberfl√§che</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Benutzerprofil  <br/>
</strong>(erwartete Nutzer:innen)
   </td>
   <td>Data Scientists, Datenbankbeauftragte
   </td>
  </tr>
  <tr>
   <td><strong>Benutzerinteraktion  <br/>
</strong>(erwartete Nutzung)
   </td>
   <td>Hochladen von Dateien, Datenzusammenf√ºhrung, -bereinigung, -strukturierung, -normalisierung und -transformation, Export von Dateien
   </td>
  </tr>
  <tr>
   <td><strong>Benutzeroberfl√§che</strong>
   </td>
   <td>browserbasiertes GUI
   </td>
  </tr>
  <tr>
   <td><strong>Visualisierungen </strong>
<br/>
(Analyse-, Input-, Outputkonfigurationen)
   </td>
   <td> ‚úÖ
   </td>
  </tr>
  <tr>
   <td colspan="2" style="text-align: center;font-size: 1.2em" ><strong>Benutzerverwaltung</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Personenverwaltung</strong>
   </td>
   <td>‚ùå
   </td>
  </tr>
  <tr>
   <td><strong>Interne Kommunikationsm√∂glichkeiten  <br/>
</strong>(z. B. Annotationsrichtlinen, Kommentarfunktionen, ‚Ä¶)
   </td>
   <td>‚ùå
   </td>
  </tr>
  <tr>
   <td colspan="2" style="text-align: center;font-size: 1.2em" ><strong>Daten- und Toolverwaltung</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Zentrale/dezentrale Verwaltungsm√∂glichkeit</strong>
   </td>
   <td>‚úÖ mehrere Projekte m√∂glich
   </td>
  </tr>
  <tr>
   <td><strong>Versionskontrolle</strong>
   </td>
   <td>‚úÖ jegliche √Ñnderungen k√∂nnen nachverfolgt und r√ºckg√§ngig gemacht bzw. wiederhergestellt werden
   </td>
  </tr>
  <tr>
   <td><strong>Projektspezifische Einstellungen</strong>
   </td>
   <td>‚úÖ
   </td>
  </tr>
  <tr>
   <td><strong>API</strong>
   </td>
   <td>‚úÖ f√ºr Reconciliation
   </td>
  </tr>
  <tr>
   <td><strong>M√∂glichkeit auf simultanes Arbeiten </strong>
   </td>
   <td>‚ùå
   </td>
  </tr>
  <tr>
   <td colspan="2" style="text-align: center;font-size: 1.2em" ><strong>Datenupload</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Unterst√ºtzte Dateiformate</strong>
   </td>
   <td>CSV, TSV, TXT, JSON, XML, ODS, XLS, XLSX, PX, MARC, RDF(JSON-LD, N3, N-Triples, Turtle, RDF/XML), Wikitext
<br/>
Importm√∂glichkeiten auch √ºber Weblinks, SQL-Datenbank oder Google Drive
   </td>
  </tr>
  <tr>
   <td><strong>Informationen zur Datensicherheit</strong>
   </td>
   <td>[nicht anwendbar, da lokale Ausf√ºhrung]
   </td>
  </tr>
  <tr>
   <td><strong>Zug√§nglichkeit von verschiedenen Standorten/Ger√§ten</strong>
   </td>
   <td>‚ùå
   </td>
  </tr>
  <tr>
   <td><strong>Einschr√§nkungen hinsichtlich der Datenmenge</strong>
   </td>
   <td>max. 1 GB
   </td>
  </tr>
  <tr>
   <td><strong>Verlustfreier Upload von bereits bearbeiteten Dokumenten </strong>
   </td>
   <td>‚úÖ
   </td>
  </tr>
  <tr>
   <td><strong>Unterst√ºtzung von IIIF-Import</strong>
   </td>
   <td>[nicht anwendbar]
   </td>
  </tr>
  <tr>
   <td colspan="2" style="text-align: center;font-size: 1.2em" ><strong>Datenbearbeitung (Normalisierungstool)</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Komplexit√§tsgrad der Normalisierung <br/>
</strong>(z. B. Verf√ºgbarkeit von Buttons, Drag&Drop-Funktion, ‚Ä¶)
   </td>
   <td>‚úÖButtons f√ºr √úbernahme von Vorschl√§gen, Liste f√ºr Standardservices verf√ºgbar
   </td>
  </tr>
  <tr>
   <td><strong>Reconciliation-M√∂glichkeiten entsprechend bestimmten Standards f√ºr digitale Editionen </strong>
   </td>
   <td>‚úÖWikidata, GND, GeoNames, Pleiades, etc.
   </td>
  </tr>
  <tr>
   <td><strong>Anpassungsm√∂glichkeit und Validierung entsprechend projektspezifischen Konventionen/Schemata</strong>
   </td>
   <td>‚úÖ
   </td>
  </tr>
  <tr>
   <td colspan="2" style="text-align: center;font-size: 1.2em" ><strong>Datenexport</strong>
   </td>
  </tr>
  <tr>
   <td><strong>Unterst√ºtzte Dateiformate</strong>
   </td>
   <td>TSV, CSV, XLS, XSLX, HTML, ODF, SQL, TXT (Templatingm√∂glichkeit f√ºr JSON, XML usw.)
   </td>
  </tr>
  <tr>
   <td><strong>Datenverlust  <br/>
</strong>(nicht vollst√§ndiger Erhalt von Annotationen, die bereits vor Verwendung des Tools gemacht wurden)
   </td>
   <td>[nicht anwendbar]
   </td>
  </tr>
  <tr>
   <td><strong>Validierungsm√∂glichkeit f√ºr TEI-XML vor Export</strong>
   </td>
   <td>[nicht anwendbar, da keine M√∂glichkeit auf XML-Export]
   </td>
  </tr>
  <tr>
   <td><strong>Datenaufbewahrung nach Export</strong>
   </td>
   <td>[nicht anwendbar, da lokale Ausf√ºhrung]
   </td>
  </tr>
</table>

